# üèóÔ∏è Enterprise-Grade AI Image Analyzer

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?logo=docker&logoColor=white)](https://www.docker.com/)
[![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?logo=kubernetes&logoColor=white)](https://kubernetes.io/)
[![Redis](https://img.shields.io/badge/redis-%23DD0031.svg?logo=redis&logoColor=white)](https://redis.io)
[![PostgreSQL](https://img.shields.io/badge/postgres-%23316192.svg?logo=postgresql&logoColor=white)](https://postgresql.org)

A production-ready microservices architecture implementing **7 critical enterprise patterns** used by major tech companies like Google, Netflix, and Spotify.

## ÔøΩ Architecture Overview

This project demonstrates **senior-level backend engineering** with real-world patterns:

- **üîê JWT + RBAC Authentication** - Token-based auth with role hierarchies
- **‚ö° API Rate Limiting** - Token bucket & sliding window algorithms  
- **üóÑÔ∏è Database Integration** - PostgreSQL with SQLAlchemy ORM & connection pooling
- **üöÄ Redis Caching** - Cache-aside patterns, graceful degradation, circuit breakers
- **üìä Observability** - Prometheus metrics, structured logging, distributed tracing
- **üê≥ Containerization** - Production Docker with multi-stage builds & security
- **‚ò∏Ô∏è Kubernetes Orchestration** - Auto-scaling, rolling deployments, resource management

## üöÄ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- Kubernetes cluster (optional)

### Local Development
```bash
# Clone and setup
git clone https://github.com/scott-ai-maker/ai-image-analyzer.git
cd ai-image-analyzer

# Start services
docker-compose up -d

# Run main application
python -m app.main
```

### Production Deployment
```bash
# Build production container
docker build -f deployment/docker/Dockerfile.production -t ai-analyzer:prod .

# Deploy to Kubernetes
kubectl apply -f deployment/kubernetes/
```

## üìÅ Project Structure

## üê≥ Docker Deployment

### Development with Docker Compose

```bash
# Build and run with monitoring
docker-compose --profile monitoring up --build

# Or just the API
docker-compose up --build
```

### Production Docker

```bash
# Build optimized image
docker build -t ai-image-analyzer:latest .

# Run with environment file
docker run --rm -p 8000:8000 --env-file .env ai-image-analyzer:latest
```

## üì° API Usage

### Analyze Image from URL

```bash
curl -X POST "http://localhost:8000/api/v1/analyze/url" \
  -H "Authorization: Bearer your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "image_url": "https://example.com/photo.jpg",
    "confidence_threshold": "medium",
    "max_objects": 10,
    "include_metadata": true
  }'
```

### Upload and Analyze Image

```bash
curl -X POST "http://localhost:8000/api/v1/analyze/upload" \
  -H "Authorization: Bearer your-api-key" \
  -F "image=@photo.jpg" \
  -F "confidence_threshold=high" \
  -F "max_objects=20"
```

### Response Format

```json
{
  "request_id": "123e4567-e89b-12d3-a456-426614174000",
  "timestamp": "2024-01-15T10:30:00Z",
  "detected_objects": [
    {
      "object_id": "obj_1_1642249800000",
      "name": "person",
      "confidence": 0.85,
      "bounding_box": {
        "x": 0.1,
        "y": 0.2,
        "width": 0.3,
        "height": 0.4
      }
    }
  ],
  "image_metadata": {
    "width": 1920,
    "height": 1080,
    "format": "jpeg",
    "size_bytes": 245760,
    "color_space": "RGB"
  },
  "processing_time_ms": 150.5,
  "confidence_threshold": 0.5,
  "total_objects_detected": 1
}
```

## üß™ Development

### Run Tests

```bash
# Full test suite with coverage
./dev.sh test

# Specific test categories
pytest tests/test_models.py -v
pytest tests/test_api.py -v --cov=src
```

### Code Quality

```bash
# Run all quality checks
./dev.sh lint

# Fix formatting
./dev.sh format

# Individual tools
black src/ tests/
isort src/ tests/
flake8 src/
mypy src/
```

### Development Commands

```bash
./dev.sh setup          # Initial setup
./dev.sh dev            # Start development server  
./dev.sh test           # Run test suite
./dev.sh lint           # Code quality checks
./dev.sh format         # Fix formatting
./dev.sh docker-build   # Build Docker image
./dev.sh docker-run     # Run Docker container
```

## üìä Monitoring

### Health Check

```bash
curl http://localhost:8000/health
```

### Metrics

```bash
curl http://localhost:8000/metrics
```

### Logging

- **Development**: Pretty console output
- **Production**: Structured JSON logs
- **Features**: Request correlation, error tracking, performance metrics

## üîí Security

- **Authentication**: API key-based (configurable)
- **Input Validation**: Comprehensive Pydantic validation
- **File Security**: Size limits, type checking, malware protection
- **Secrets Management**: Environment variables, Azure Key Vault support
- **Container Security**: Non-root execution, minimal attack surface

## üöÄ Production Deployment

### Environment Configuration

```bash
# Production environment variables
ENVIRONMENT=production
DEBUG=false
API_KEYS=key1,key2,key3
AZURE_CLIENT_ID=managed-identity-client-id  # For managed identity
```

### Azure Deployment Options

1. **Azure Container Instances**
2. **Azure Kubernetes Service (AKS)**
3. **Azure App Service**
4. **Azure Functions** (with modifications)

### Monitoring Integration

- **Azure Monitor** for application insights
- **Prometheus + Grafana** for metrics
- **Azure Log Analytics** for centralized logging

## üìà Performance

- **Async Architecture**: Non-blocking I/O for high concurrency
- **Connection Pooling**: Optimized HTTP client management
- **Resource Limits**: Configurable timeouts and size limits
- **Caching**: Efficient image processing pipelines

### Benchmarks

- **Throughput**: 100+ concurrent requests
- **Latency**: ~150ms average processing time
- **Memory**: <100MB baseline usage
- **Scale**: Horizontal scaling with load balancers

## ü§ù Contributing

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** changes (`git commit -m 'Add amazing feature'`)
4. **Push** to branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Guidelines

- **Tests**: Maintain >90% code coverage
- **Types**: Full type annotations required
- **Docs**: Update documentation for API changes
- **Style**: Follow Black + isort + flake8 standards

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details.

## üôã‚Äç‚ôÇÔ∏è Support

- **Documentation**: [docs/](docs/) folder
- **Issues**: GitHub Issues
- **Security**: Report privately to engineering@company.com

---

**Built with ‚ù§Ô∏è for enterprise AI applications**
